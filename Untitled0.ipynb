{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"9CEkzenGp47O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704211603979,"user_tz":-330,"elapsed":28721,"user":{"displayName":"Raj Patel","userId":"15736742031330415268"}},"outputId":"afefeb9c-d52e-498a-f481-136af46cb0cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"dkS1ftBM_Sk1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704211607033,"user_tz":-330,"elapsed":603,"user":{"displayName":"Raj Patel","userId":"15736742031330415268"}},"outputId":"3fd949e8-57ce-4748-a950-909710f77b3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/HAT2\n"]}],"source":["cd /content/drive/MyDrive/HAT2"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"hgYH_QeB_aAz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704211639938,"user_tz":-330,"elapsed":32182,"user":{"displayName":"Raj Patel","userId":"15736742031330415268"}},"outputId":"76995d16-a791-4d3a-e93e-aa722bd4b882"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/setuptools/__init__.py:84: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n","!!\n","\n","        ********************************************************************************\n","        Requirements should be satisfied by a PEP 517 installer.\n","        If you are using pip, you can try `pip install --use-pep517`.\n","        ********************************************************************************\n","\n","!!\n","  dist.fetch_build_eggs(dist.setup_requires)\n","running develop\n","/usr/local/lib/python3.10/dist-packages/setuptools/command/develop.py:40: EasyInstallDeprecationWarning: easy_install command is deprecated.\n","!!\n","\n","        ********************************************************************************\n","        Please avoid running ``setup.py`` and ``easy_install``.\n","        Instead, use pypa/build, pypa/installer, pypa/build or\n","        other standards-based tools.\n","\n","        See https://github.com/pypa/setuptools/issues/917 for details.\n","        ********************************************************************************\n","\n","!!\n","  easy_install.initialize_options(self)\n","/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n","!!\n","\n","        ********************************************************************************\n","        Please avoid running ``setup.py`` directly.\n","        Instead, use pypa/build, pypa/installer, pypa/build or\n","        other standards-based tools.\n","\n","        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n","        ********************************************************************************\n","\n","!!\n","  self.initialize_options()\n","running egg_info\n","writing hat.egg-info/PKG-INFO\n","writing dependency_links to hat.egg-info/dependency_links.txt\n","writing requirements to hat.egg-info/requires.txt\n","writing top-level names to hat.egg-info/top_level.txt\n","reading manifest file 'hat.egg-info/SOURCES.txt'\n","adding license file 'LICENSE'\n","writing manifest file 'hat.egg-info/SOURCES.txt'\n","running build_ext\n","Creating /usr/local/lib/python3.10/dist-packages/hat.egg-link (link to .)\n","Adding hat 0.1.0 to easy-install.pth file\n","\n","Installed /content/drive/MyDrive/HAT2\n","Processing dependencies for hat==0.1.0\n","Searching for basicsr==1.3.4.9\n","Reading https://pypi.org/simple/basicsr/\n","Downloading https://files.pythonhosted.org/packages/f0/83/7692977f9bb0ea8be5bb859c7dcd4bcf38071fc963cc2950d69f21b07939/basicsr-1.3.4.9.tar.gz#sha256=87ba1bc09bd5b0c7d257295c90507cfab70edb880bf569143dd5a614f457ead7\n","Best match: basicsr 1.3.4.9\n","Processing basicsr-1.3.4.9.tar.gz\n","Writing /tmp/easy_install-al4kysfh/basicsr-1.3.4.9/setup.cfg\n","Running basicsr-1.3.4.9/setup.py -q bdist_egg --dist-dir /tmp/easy_install-al4kysfh/basicsr-1.3.4.9/egg-dist-tmp-djv6kn4n\n","/usr/local/lib/python3.10/dist-packages/setuptools/__init__.py:84: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n","!!\n","\n","        ********************************************************************************\n","        Requirements should be satisfied by a PEP 517 installer.\n","        If you are using pip, you can try `pip install --use-pep517`.\n","        ********************************************************************************\n","\n","!!\n","  dist.fetch_build_eggs(dist.setup_requires)\n","/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n","!!\n","\n","        ********************************************************************************\n","        Please avoid running ``setup.py`` directly.\n","        Instead, use pypa/build, pypa/installer, pypa/build or\n","        other standards-based tools.\n","\n","        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n","        ********************************************************************************\n","\n","!!\n","  self.initialize_options()\n","/usr/local/lib/python3.10/dist-packages/setuptools/command/build_py.py:201: _Warning: Package 'basicsr.ops.dcn.src' is absent from the `packages` configuration.\n","!!\n","\n","        ********************************************************************************\n","        ############################\n","        # Package would be ignored #\n","        ############################\n","        Python recognizes 'basicsr.ops.dcn.src' as an importable package[^1],\n","        but it is absent from setuptools' `packages` configuration.\n","\n","        This leads to an ambiguous overall configuration. If you want to distribute this\n","        package, please make sure that 'basicsr.ops.dcn.src' is explicitly added\n","        to the `packages` configuration field.\n","\n","        Alternatively, you can also rely on setuptools' discovery methods\n","        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n","        instead of `find_packages(...)`/`find:`).\n","\n","        You can read more about \"package discovery\" on setuptools documentation page:\n","\n","        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n","\n","        If you don't want 'basicsr.ops.dcn.src' to be distributed and are\n","        already explicitly excluding 'basicsr.ops.dcn.src' via\n","        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n","        you can try to use `exclude_package_data`, or `include-package-data=False` in\n","        combination with a more fine grained `package-data` configuration.\n","\n","        You can read more about \"package data files\" on setuptools documentation page:\n","\n","        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n","\n","\n","        [^1]: For Python, any directory (with suitable naming) can be imported,\n","              even if it does not contain any `.py` files.\n","              On the other hand, currently there is no concept of package data\n","              directory, all directories are treated like packages.\n","        ********************************************************************************\n","\n","!!\n","  check.warn(importable)\n","/usr/local/lib/python3.10/dist-packages/setuptools/command/build_py.py:201: _Warning: Package 'basicsr.ops.fused_act.src' is absent from the `packages` configuration.\n","!!\n","\n","        ********************************************************************************\n","        ############################\n","        # Package would be ignored #\n","        ############################\n","        Python recognizes 'basicsr.ops.fused_act.src' as an importable package[^1],\n","        but it is absent from setuptools' `packages` configuration.\n","\n","        This leads to an ambiguous overall configuration. If you want to distribute this\n","        package, please make sure that 'basicsr.ops.fused_act.src' is explicitly added\n","        to the `packages` configuration field.\n","\n","        Alternatively, you can also rely on setuptools' discovery methods\n","        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n","        instead of `find_packages(...)`/`find:`).\n","\n","        You can read more about \"package discovery\" on setuptools documentation page:\n","\n","        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n","\n","        If you don't want 'basicsr.ops.fused_act.src' to be distributed and are\n","        already explicitly excluding 'basicsr.ops.fused_act.src' via\n","        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n","        you can try to use `exclude_package_data`, or `include-package-data=False` in\n","        combination with a more fine grained `package-data` configuration.\n","\n","        You can read more about \"package data files\" on setuptools documentation page:\n","\n","        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n","\n","\n","        [^1]: For Python, any directory (with suitable naming) can be imported,\n","              even if it does not contain any `.py` files.\n","              On the other hand, currently there is no concept of package data\n","              directory, all directories are treated like packages.\n","        ********************************************************************************\n","\n","!!\n","  check.warn(importable)\n","/usr/local/lib/python3.10/dist-packages/setuptools/command/build_py.py:201: _Warning: Package 'basicsr.ops.upfirdn2d.src' is absent from the `packages` configuration.\n","!!\n","\n","        ********************************************************************************\n","        ############################\n","        # Package would be ignored #\n","        ############################\n","        Python recognizes 'basicsr.ops.upfirdn2d.src' as an importable package[^1],\n","        but it is absent from setuptools' `packages` configuration.\n","\n","        This leads to an ambiguous overall configuration. If you want to distribute this\n","        package, please make sure that 'basicsr.ops.upfirdn2d.src' is explicitly added\n","        to the `packages` configuration field.\n","\n","        Alternatively, you can also rely on setuptools' discovery methods\n","        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n","        instead of `find_packages(...)`/`find:`).\n","\n","        You can read more about \"package discovery\" on setuptools documentation page:\n","\n","        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n","\n","        If you don't want 'basicsr.ops.upfirdn2d.src' to be distributed and are\n","        already explicitly excluding 'basicsr.ops.upfirdn2d.src' via\n","        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n","        you can try to use `exclude_package_data`, or `include-package-data=False` in\n","        combination with a more fine grained `package-data` configuration.\n","\n","        You can read more about \"package data files\" on setuptools documentation page:\n","\n","        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n","\n","\n","        [^1]: For Python, any directory (with suitable naming) can be imported,\n","              even if it does not contain any `.py` files.\n","              On the other hand, currently there is no concept of package data\n","              directory, all directories are treated like packages.\n","        ********************************************************************************\n","\n","!!\n","  check.warn(importable)\n","Adding basicsr 1.3.4.9 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.10/dist-packages/basicsr-1.3.4.9-py3.10.egg\n","Searching for einops\n","Reading https://pypi.org/simple/einops/\n","Downloading https://files.pythonhosted.org/packages/29/0b/2d1c0ebfd092e25935b86509a9a817159212d82aa43d7fb07eca4eeff2c2/einops-0.7.0-py3-none-any.whl#sha256=0f3096f26b914f465f6ff3c66f5478f9a5e380bb367ffc6493a68143fbbf1fd1\n","Best match: einops 0.7.0\n","Processing einops-0.7.0-py3-none-any.whl\n","Installing einops-0.7.0-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n","Adding einops 0.7.0 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.10/dist-packages/einops-0.7.0-py3.10.egg\n","Searching for yapf\n","Reading https://pypi.org/simple/yapf/\n","Downloading https://files.pythonhosted.org/packages/66/c9/d4b03b2490107f13ebd68fe9496d41ae41a7de6275ead56d0d4621b11ffd/yapf-0.40.2-py3-none-any.whl#sha256=adc8b5dd02c0143108878c499284205adb258aad6db6634e5b869e7ee2bd548b\n","Best match: yapf 0.40.2\n","Processing yapf-0.40.2-py3-none-any.whl\n","Installing yapf-0.40.2-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n","Adding yapf 0.40.2 to easy-install.pth file\n","Installing yapf script to /usr/local/bin\n","Installing yapf-diff script to /usr/local/bin\n","\n","Installed /usr/local/lib/python3.10/dist-packages/yapf-0.40.2-py3.10.egg\n","Searching for tb-nightly\n","Reading https://pypi.org/simple/tb-nightly/\n","Downloading https://files.pythonhosted.org/packages/77/62/afeeb0751a3cca1c730d1dcbd32fbe778d3559b52b29674005f107cb7fe0/tb_nightly-2.16.0a20240102-py3-none-any.whl#sha256=134b3c6d3ec4028eacf5a3e60697e4635e607a24ce11ae77c97c39f104c52506\n","Best match: tb-nightly 2.16.0a20240102\n","Processing tb_nightly-2.16.0a20240102-py3-none-any.whl\n","Installing tb_nightly-2.16.0a20240102-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n","Adding tb-nightly 2.16.0a20240102 to easy-install.pth file\n","Installing tensorboard script to /usr/local/bin\n","\n","Installed /usr/local/lib/python3.10/dist-packages/tb_nightly-2.16.0a20240102-py3.10.egg\n","Searching for lmdb\n","Reading https://pypi.org/simple/lmdb/\n","Downloading https://files.pythonhosted.org/packages/83/67/8f32a70336d3ff1149cbd31e5a877997384f78c3940edc0abff95c8a5601/lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=6f8018a947608c4be0dc885c90f477a600be1b71285059a9c68280d36b3fb29b\n","Best match: lmdb 1.4.1\n","Processing lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n","Installing lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl to /usr/local/lib/python3.10/dist-packages\n","Adding lmdb 1.4.1 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.10/dist-packages/lmdb-1.4.1-py3.10-linux-x86_64.egg\n","Searching for addict\n","Reading https://pypi.org/simple/addict/\n","Downloading https://files.pythonhosted.org/packages/6a/00/b08f23b7d7e1e14ce01419a467b583edbb93c6cdb8654e54a9cc579cd61f/addict-2.4.0-py3-none-any.whl#sha256=249bb56bbfd3cdc2a004ea0ff4c2b6ddc84d53bc2194761636eb314d5cfa5dfc\n","Best match: addict 2.4.0\n","Processing addict-2.4.0-py3-none-any.whl\n","Installing addict-2.4.0-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n","Adding addict 2.4.0 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.10/dist-packages/addict-2.4.0-py3.10.egg\n","Searching for tf-keras-nightly\n","Reading https://pypi.org/simple/tf-keras-nightly/\n","Downloading https://files.pythonhosted.org/packages/19/40/36bc44a59aea9da66a693b53afdd11ed661fc49c423cca8daf4bc96e5565/tf_keras_nightly-2.16.0.dev2023123010-py3-none-any.whl#sha256=85b5e635a92abf7348e019d2b43cfef05b40d354934821e94c3485cc7d3aa89e\n","Best match: tf-keras-nightly 2.16.0.dev2023123010\n","Processing tf_keras_nightly-2.16.0.dev2023123010-py3-none-any.whl\n","Installing tf_keras_nightly-2.16.0.dev2023123010-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n","Adding tf-keras-nightly 2.16.0.dev2023123010 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.10/dist-packages/tf_keras_nightly-2.16.0.dev2023123010-py3.10.egg\n","Searching for torch==2.1.0+cu121\n","Best match: torch 2.1.0+cu121\n","Adding torch 2.1.0+cu121 to easy-install.pth file\n","Installing convert-caffe2-to-onnx script to /usr/local/bin\n","Installing convert-onnx-to-caffe2 script to /usr/local/bin\n","Installing torchrun script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for tqdm==4.66.1\n","Best match: tqdm 4.66.1\n","Adding tqdm 4.66.1 to easy-install.pth file\n","Installing tqdm script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for torchvision==0.16.0+cu121\n","Best match: torchvision 0.16.0+cu121\n","Adding torchvision 0.16.0+cu121 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for scipy==1.11.4\n","Best match: scipy 1.11.4\n","Adding scipy 1.11.4 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for scikit-image==0.19.3\n","Best match: scikit-image 0.19.3\n","Adding scikit-image 0.19.3 to easy-install.pth file\n","Installing skivi script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for requests==2.31.0\n","Best match: requests 2.31.0\n","Adding requests 2.31.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for PyYAML==6.0.1\n","Best match: PyYAML 6.0.1\n","Adding PyYAML 6.0.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for Pillow==9.4.0\n","Best match: Pillow 9.4.0\n","Adding Pillow 9.4.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for opencv-python==4.8.0.76\n","Best match: opencv-python 4.8.0.76\n","Adding opencv-python 4.8.0.76 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for numpy==1.23.5\n","Best match: numpy 1.23.5\n","Adding numpy 1.23.5 to easy-install.pth file\n","Installing f2py script to /usr/local/bin\n","Installing f2py3 script to /usr/local/bin\n","Installing f2py3.10 script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for future==0.18.3\n","Best match: future 0.18.3\n","Adding future 0.18.3 to easy-install.pth file\n","Installing futurize script to /usr/local/bin\n","Installing pasteurize script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for triton==2.1.0\n","Best match: triton 2.1.0\n","Adding triton 2.1.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for fsspec==2023.6.0\n","Best match: fsspec 2023.6.0\n","Adding fsspec 2023.6.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for Jinja2==3.1.2\n","Best match: Jinja2 3.1.2\n","Adding Jinja2 3.1.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for networkx==3.2.1\n","Best match: networkx 3.2.1\n","Adding networkx 3.2.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for sympy==1.12\n","Best match: sympy 1.12\n","Adding sympy 1.12 to easy-install.pth file\n","Installing isympy script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for typing-extensions==4.5.0\n","Best match: typing-extensions 4.5.0\n","Adding typing-extensions 4.5.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for filelock==3.13.1\n","Best match: filelock 3.13.1\n","Adding filelock 3.13.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for tomli==2.0.1\n","Best match: tomli 2.0.1\n","Adding tomli 2.0.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for platformdirs==4.1.0\n","Best match: platformdirs 4.1.0\n","Adding platformdirs 4.1.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for importlib-metadata==7.0.0\n","Best match: importlib-metadata 7.0.0\n","Adding importlib-metadata 7.0.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for werkzeug==3.0.1\n","Best match: werkzeug 3.0.1\n","Adding werkzeug 3.0.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for tensorboard-data-server==0.7.2\n","Best match: tensorboard-data-server 0.7.2\n","Adding tensorboard-data-server 0.7.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for six==1.16.0\n","Best match: six 1.16.0\n","Adding six 1.16.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for setuptools==67.7.2\n","Best match: setuptools 67.7.2\n","Adding setuptools 67.7.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for protobuf==3.20.3\n","Best match: protobuf 3.20.3\n","Adding protobuf 3.20.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for Markdown==3.5.1\n","Best match: Markdown 3.5.1\n","Adding Markdown 3.5.1 to easy-install.pth file\n","Installing markdown_py script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for google-auth-oauthlib==1.2.0\n","Best match: google-auth-oauthlib 1.2.0\n","Adding google-auth-oauthlib 1.2.0 to easy-install.pth file\n","Installing google-oauthlib-tool script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for google-auth==2.17.3\n","Best match: google-auth 2.17.3\n","Adding google-auth 2.17.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for grpcio==1.60.0\n","Best match: grpcio 1.60.0\n","Adding grpcio 1.60.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for absl-py==1.4.0\n","Best match: absl-py 1.4.0\n","Adding absl-py 1.4.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for packaging==23.2\n","Best match: packaging 23.2\n","Adding packaging 23.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for pywavelets==1.5.0\n","Best match: pywavelets 1.5.0\n","Adding pywavelets 1.5.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for tifffile==2023.12.9\n","Best match: tifffile 2023.12.9\n","Adding tifffile 2023.12.9 to easy-install.pth file\n","Installing lsm2bin script to /usr/local/bin\n","Installing tiff2fsspec script to /usr/local/bin\n","Installing tiffcomment script to /usr/local/bin\n","Installing tifffile script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for imageio==2.31.6\n","Best match: imageio 2.31.6\n","Adding imageio 2.31.6 to easy-install.pth file\n","Installing imageio_download_bin script to /usr/local/bin\n","Installing imageio_remove_bin script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for certifi==2023.11.17\n","Best match: certifi 2023.11.17\n","Adding certifi 2023.11.17 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for urllib3==2.0.7\n","Best match: urllib3 2.0.7\n","Adding urllib3 2.0.7 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for idna==3.6\n","Best match: idna 3.6\n","Adding idna 3.6 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for charset-normalizer==3.3.2\n","Best match: charset-normalizer 3.3.2\n","Adding charset-normalizer 3.3.2 to easy-install.pth file\n","Installing normalizer script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for MarkupSafe==2.1.3\n","Best match: MarkupSafe 2.1.3\n","Adding MarkupSafe 2.1.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for mpmath==1.3.0\n","Best match: mpmath 1.3.0\n","Adding mpmath 1.3.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for zipp==3.17.0\n","Best match: zipp 3.17.0\n","Adding zipp 3.17.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for requests-oauthlib==1.3.1\n","Best match: requests-oauthlib 1.3.1\n","Adding requests-oauthlib 1.3.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for rsa==4.9\n","Best match: rsa 4.9\n","Adding rsa 4.9 to easy-install.pth file\n","Installing pyrsa-decrypt script to /usr/local/bin\n","Installing pyrsa-encrypt script to /usr/local/bin\n","Installing pyrsa-keygen script to /usr/local/bin\n","Installing pyrsa-priv2pub script to /usr/local/bin\n","Installing pyrsa-sign script to /usr/local/bin\n","Installing pyrsa-verify script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for pyasn1-modules==0.3.0\n","Best match: pyasn1-modules 0.3.0\n","Adding pyasn1-modules 0.3.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for cachetools==5.3.2\n","Best match: cachetools 5.3.2\n","Adding cachetools 5.3.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for oauthlib==3.2.2\n","Best match: oauthlib 3.2.2\n","Adding oauthlib 3.2.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Searching for pyasn1==0.5.1\n","Best match: pyasn1 0.5.1\n","Adding pyasn1 0.5.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.10/dist-packages\n","Finished processing dependencies for hat==0.1.0\n"]}],"source":["!python setup.py develop"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Sd62Cf1n_ieh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704213720952,"user_tz":-330,"elapsed":151512,"user":{"displayName":"Raj Patel","userId":"15736742031330415268"}},"outputId":"84fa91f4-73a7-4e5f-b251-386be4661a1c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Disable distributed.\n","Path already exists. Rename it to /content/drive/MyDrive/HAT2/experiments/train_HAT_archived_20240102_163931\n","Path already exists. Rename it to /content/drive/MyDrive/HAT2/tb_logger/train_HAT_archived_20240102_163931\n","2024-01-02 16:39:31,759 INFO: \n","                ____                _       _____  ____\n","               / __ ) ____ _ _____ (_)_____/ ___/ / __ \\\n","              / __  |/ __ `// ___// // ___/\\__ \\ / /_/ /\n","             / /_/ // /_/ /(__  )/ // /__ ___/ // _, _/\n","            /_____/ \\__,_//____//_/ \\___//____//_/ |_|\n","     ______                   __   __                 __      __\n","    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /\n","   / / __ / __ \\ / __ \\ / __  /  / /   / / / // ___// //_/  / /\n","  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/\n","  \\____/ \\____/ \\____/ \\____/  /_____/\\____/ \\___//_/|_|  (_)\n","    \n","Version Information: \n","\tBasicSR: 1.3.4.9\n","\tPyTorch: 2.1.0+cu121\n","\tTorchVision: 0.16.0+cu121\n","2024-01-02 16:39:31,760 INFO: \n","  name: train_HAT\n","  model_type: HATModel\n","  scale: 4\n","  num_gpu: 1\n","  manual_seed: 0\n","  datasets:[\n","    train:[\n","      name: DIV2K\n","      type: PairedImageDataset\n","      dataroot_gt: datasets/DIV2K/train/HR\n","      dataroot_lq: datasets/DIV2K/train/X4\n","      io_backend:[\n","        type: disk\n","      ]\n","      gt_size: 128\n","      use_hflip: True\n","      use_rot: True\n","      use_shuffle: True\n","      num_worker_per_gpu: 16\n","      batch_size_per_gpu: 4\n","      dataset_enlarge_ratio: 1\n","      prefetch_mode: None\n","      phase: train\n","      scale: 4\n","    ]\n","    val_1:[\n","      name: CelebA-HQ\n","      type: PairedImageDataset\n","      dataroot_gt: datasets/Set5train/HR\n","      dataroot_lq: datasets/Set5train/X4\n","      io_backend:[\n","        type: disk\n","      ]\n","      phase: val\n","      scale: 4\n","    ]\n","  ]\n","  network_g:[\n","    type: HAT\n","    upscale: 4\n","    in_chans: 3\n","    img_size: 64\n","    window_size: 16\n","    compress_ratio: 3\n","    squeeze_factor: 30\n","    conv_scale: 0.01\n","    overlap_ratio: 0.5\n","    img_range: 1.0\n","    depths: [6, 6, 6, 6, 6, 6, 6, 6]\n","    embed_dim: 180\n","    num_heads: [6, 6, 6, 6, 6, 6, 6, 6]\n","    mlp_ratio: 2\n","    upsampler: pixelshuffle\n","    resi_connection: 1conv\n","  ]\n","  path:[\n","    pretrain_network_g: None\n","    param_key_g: params_ema\n","    strict_load_g: True\n","    resume_state: None\n","    experiments_root: /content/drive/MyDrive/HAT2/experiments/train_HAT\n","    models: /content/drive/MyDrive/HAT2/experiments/train_HAT/models\n","    training_states: /content/drive/MyDrive/HAT2/experiments/train_HAT/training_states\n","    log: /content/drive/MyDrive/HAT2/experiments/train_HAT\n","    visualization: /content/drive/MyDrive/HAT2/experiments/train_HAT/visualization\n","  ]\n","  train:[\n","    ema_decay: 0.999\n","    optim_g:[\n","      type: Adam\n","      lr: 0.0001\n","      weight_decay: 0\n","      betas: [0.9, 0.99]\n","    ]\n","    scheduler:[\n","      type: MultiStepLR\n","      milestones: [250000, 400000, 450000, 475000]\n","      gamma: 0.5\n","    ]\n","    total_iter: 500000\n","    warmup_iter: -1\n","    pixel_opt:[\n","      type: L1Loss\n","      loss_weight: 1.0\n","      reduction: mean\n","    ]\n","  ]\n","  val:[\n","    val_freq: 5000.0\n","    save_img: False\n","    pbar: False\n","    metrics:[\n","      psnr:[\n","        type: calculate_psnr\n","        crop_border: 4\n","        test_y_channel: True\n","        better: higher\n","      ]\n","      ssim:[\n","        type: calculate_ssim\n","        crop_border: 4\n","        test_y_channel: True\n","        better: higher\n","      ]\n","    ]\n","  ]\n","  logger:[\n","    print_freq: 100\n","    save_checkpoint_freq: 5000.0\n","    use_tb_logger: True\n","    wandb:[\n","      project: None\n","      resume_id: None\n","    ]\n","  ]\n","  dist_params:[\n","    backend: nccl\n","    port: 29500\n","  ]\n","  dist: False\n","  rank: 0\n","  world_size: 1\n","  auto_resume: False\n","  is_train: True\n","  root_path: /content/drive/MyDrive/HAT2\n","\n","2024-01-02 16:39:32.251124: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-01-02 16:39:32.251181: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-01-02 16:39:32.252998: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-01-02 16:39:33.840946: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-01-02 16:39:35,103 INFO: Dataset [PairedImageDataset] - DIV2K is built.\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","2024-01-02 16:39:35,104 INFO: Training statistics:\n","\tNumber of train images: 5\n","\tDataset enlarge ratio: 1\n","\tBatch size per gpu: 4\n","\tWorld size (gpu number): 1\n","\tRequire iter number per epoch: 2\n","\tTotal epochs: 250000; iters: 500000.\n","2024-01-02 16:39:35,106 INFO: Dataset [PairedImageDataset] - CelebA-HQ is built.\n","2024-01-02 16:39:35,106 INFO: Number of val images/folders in CelebA-HQ: 3\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","2024-01-02 16:39:35,188 INFO: Network [HAT] is created.\n","2024-01-02 16:39:35,385 INFO: Network: HAT, with parameters: 3,245,119\n","2024-01-02 16:39:35,386 INFO: HAT(\n","  (conv_first): Sequential(\n","    (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3)\n","    (1): Conv2d(3, 180, kernel_size=(1, 1), stride=(1, 1))\n","  )\n","  (coreser): CoarseSRNet(\n","    (enc_conv1): Conv2d(180, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (enc_prelu1): PReLU(num_parameters=1)\n","    (enc_conv2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n","    (enc_prelu2): PReLU(num_parameters=1)\n","    (residual_blocks): Sequential(\n","      (0): ResidualBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (prelu1): PReLU(num_parameters=1)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (prelu2): PReLU(num_parameters=1)\n","        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): ResidualBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (prelu1): PReLU(num_parameters=1)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (prelu2): PReLU(num_parameters=1)\n","        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): ResidualBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (prelu1): PReLU(num_parameters=1)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (prelu2): PReLU(num_parameters=1)\n","        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (3): ResidualBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (prelu1): PReLU(num_parameters=1)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (prelu2): PReLU(num_parameters=1)\n","        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (dec_tconv1): ConvTranspose2d(128, 3, kernel_size=(3, 3), stride=(1, 1))\n","    (dec_conv1): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1))\n","    (dec_tconv2): ConvTranspose2d(128, 3, kernel_size=(3, 3), stride=(1, 1))\n","    (dec_conv2): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n","    (dec_tconv3): ConvTranspose2d(64, 180, kernel_size=(3, 3), stride=(1, 1))\n","  )\n","  (patch_embed): PatchEmbed(\n","    (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (patch_unembed): PatchUnEmbed()\n","  (pos_drop): Dropout(p=0.0, inplace=False)\n","  (layers): ModuleList(\n","    (0): RHAG(\n","      (residual_group): AttenBlocks(\n","        (blocks): ModuleList(\n","          (0): HAB(\n","            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=180, out_features=540, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=180, out_features=180, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (conv_block): CAB(\n","              (depthwise_separable_conv): Sequential(\n","                (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)\n","                (1): Conv2d(180, 60, kernel_size=(1, 1), stride=(1, 1))\n","              )\n","              (depthwise_separable_conv1): Sequential(\n","                (0): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)\n","                (1): Conv2d(60, 180, kernel_size=(1, 1), stride=(1, 1))\n","              )\n","              (cab): Sequential(\n","                (0): Sequential(\n","                  (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)\n","                  (1): Conv2d(180, 60, kernel_size=(1, 1), stride=(1, 1))\n","                )\n","                (1): GELU(approximate='none')\n","                (2): Sequential(\n","                  (0): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)\n","                  (1): Conv2d(60, 180, kernel_size=(1, 1), stride=(1, 1))\n","                )\n","                (3): ChannelAttention(\n","                  (attention): Sequential(\n","                    (0): AdaptiveAvgPool2d(output_size=1)\n","                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))\n","                    (2): ReLU(inplace=True)\n","                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))\n","                    (4): Sigmoid()\n","                  )\n","                )\n","              )\n","            )\n","            (drop_path): Identity()\n","            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=180, out_features=360, bias=True)\n","              (act): GELU(approximate='none')\n","              (fc2): Linear(in_features=360, out_features=180, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): HAB(\n","            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=180, out_features=540, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=180, out_features=180, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (conv_block): CAB(\n","              (depthwise_separable_conv): Sequential(\n","                (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)\n","                (1): Conv2d(180, 60, kernel_size=(1, 1), stride=(1, 1))\n","              )\n","              (depthwise_separable_conv1): Sequential(\n","                (0): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)\n","                (1): Conv2d(60, 180, kernel_size=(1, 1), stride=(1, 1))\n","              )\n","              (cab): Sequential(\n","                (0): Sequential(\n","                  (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)\n","                  (1): Conv2d(180, 60, kernel_size=(1, 1), stride=(1, 1))\n","                )\n","                (1): GELU(approximate='none')\n","                (2): Sequential(\n","                  (0): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60)\n","                  (1): Conv2d(60, 180, kernel_size=(1, 1), stride=(1, 1))\n","                )\n","                (3): ChannelAttention(\n","                  (attention): Sequential(\n","                    (0): AdaptiveAvgPool2d(output_size=1)\n","                    (1): Conv2d(180, 6, kernel_size=(1, 1), stride=(1, 1))\n","                    (2): ReLU(inplace=True)\n","                    (3): Conv2d(6, 180, kernel_size=(1, 1), stride=(1, 1))\n","                    (4): Sigmoid()\n","                  )\n","                )\n","              )\n","            )\n","            (drop_path): DropPath()\n","            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=180, out_features=360, bias=True)\n","              (act): GELU(approximate='none')\n","              (fc2): Linear(in_features=360, out_features=180, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","        )\n","        (overlap_attn): OCAB(\n","          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n","          (qkv): Linear(in_features=180, out_features=540, bias=True)\n","          (unfold): Unfold(kernel_size=(24, 24), dilation=1, padding=4, stride=16)\n","          (softmax): Softmax(dim=-1)\n","          (proj): Linear(in_features=180, out_features=180, bias=True)\n","          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=180, out_features=360, bias=True)\n","            (act): GELU(approximate='none')\n","            (fc2): Linear(in_features=360, out_features=180, bias=True)\n","            (drop): Dropout(p=0.0, inplace=False)\n","          )\n","        )\n","      )\n","      (conv): Sequential(\n","        (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)\n","        (1): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))\n","      )\n","      (patch_embed): PatchEmbed()\n","      (patch_unembed): PatchUnEmbed()\n","    )\n","  )\n","  (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)\n","  (conv_after_body): Sequential(\n","    (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)\n","    (1): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))\n","  )\n","  (conv_after): Sequential(\n","    (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)\n","    (1): Conv2d(180, 64, kernel_size=(1, 1), stride=(1, 1))\n","  )\n","  (conv_before_upsample): Sequential(\n","    (0): Sequential(\n","      (0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)\n","      (1): Conv2d(180, 64, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n","  )\n","  (upsample): Upsample(\n","    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): PixelShuffle(upscale_factor=2)\n","    (2): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): PixelShuffle(upscale_factor=2)\n","  )\n","  (conv_last): Sequential(\n","    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n","    (1): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n","  )\n",")\n","2024-01-02 16:39:35,387 INFO: Use Exponential Moving Average with decay: 0.999\n","2024-01-02 16:39:35,460 INFO: Network [HAT] is created.\n","2024-01-02 16:39:35,511 INFO: Loss [L1Loss] is created.\n","2024-01-02 16:39:35,513 INFO: Model [HATModel] is created.\n","2024-01-02 16:39:35,772 INFO: Start training from epoch: 0, iter: 0\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","2024-01-02 16:41:25,825 INFO: [train..][epoch: 99, iter:     100, lr:(1.000e-04,)] [eta: 6 days, 3:18:38, time (data): 1.100 (0.768)] l_pix: 6.7704e-02 \n","Exception ignored in: <function _releaseLock at 0x7c1298b17520>\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 228, in _releaseLock\n","    def _releaseLock():\n","KeyboardInterrupt: \n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1132, in _try_get_data\n","    data = self._data_queue.get(timeout=timeout)\n","  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 114, in get\n","    raise Empty\n","_queue.Empty\n","\n","The above exception was the direct cause of the following exception:\n","\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/HAT2/hat/train.py\", line 11, in <module>\n","    train_pipeline(root_path)\n","  File \"/usr/local/lib/python3.10/dist-packages/basicsr-1.3.4.9-py3.10.egg/basicsr/train.py\", line 157, in train_pipeline\n","    train_data = prefetcher.next()\n","  File \"/usr/local/lib/python3.10/dist-packages/basicsr-1.3.4.9-py3.10.egg/basicsr/data/prefetch_dataloader.py\", line 76, in next\n","    return next(self.loader)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n","    data = self._next_data()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1328, in _next_data\n","    idx, data = self._get_data()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1294, in _get_data\n","    success, data = self._try_get_data()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1145, in _try_get_data\n","    raise RuntimeError(f'DataLoader worker (pid(s) {pids_str}) exited unexpectedly') from e\n","RuntimeError: DataLoader worker (pid(s) 41677, 41679, 41681, 41683, 41685, 41687, 41689, 41691, 41693) exited unexpectedly\n"]}],"source":["!python hat/train.py -opt options/train/X4_scratch.yml"]},{"cell_type":"code","source":["cd datasets/data/Set5/X4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zr4Hi-lyhgGV","executionInfo":{"status":"ok","timestamp":1704037061973,"user_tz":-330,"elapsed":487,"user":{"displayName":"Raj Patel","userId":"15736742031330415268"}},"outputId":"36ac8c74-5244-4ccd-f086-1b86c9e225ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: 'datasets/data/Set5/X4'\n","/content/drive/MyDrive/HAT2\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6081,"status":"ok","timestamp":1704025983446,"user":{"displayName":"Raj Patel","userId":"15736742031330415268"},"user_tz":-330},"id":"JaeMMylohWib","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d117e43d-b03d-429e-a4d8-8b160a6f5288"},"outputs":[{"output_type":"stream","name":"stdout","text":["Disable distributed.\n","Path already exists. Rename it to /content/drive/MyDrive/HAT2/results/HAT_SRx2_archived_20231231_123259\n","2023-12-31 12:32:59,220 INFO: \n","                ____                _       _____  ____\n","               / __ ) ____ _ _____ (_)_____/ ___/ / __ \\\n","              / __  |/ __ `// ___// // ___/\\__ \\ / /_/ /\n","             / /_/ // /_/ /(__  )/ // /__ ___/ // _, _/\n","            /_____/ \\__,_//____//_/ \\___//____//_/ |_|\n","     ______                   __   __                 __      __\n","    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /\n","   / / __ / __ \\ / __ \\ / __  /  / /   / / / // ___// //_/  / /\n","  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/\n","  \\____/ \\____/ \\____/ \\____/  /_____/\\____/ \\___//_/|_|  (_)\n","    \n","Version Information: \n","\tBasicSR: 1.3.4.9\n","\tPyTorch: 2.1.0+cu121\n","\tTorchVision: 0.16.0+cu121\n","2023-12-31 12:32:59,221 INFO: \n","  name: HAT_SRx2\n","  model_type: HATModel\n","  scale: 2\n","  num_gpu: 1\n","  manual_seed: 0\n","  datasets:[\n","    test_1:[\n","      name: Set5\n","      type: PairedImageDataset\n","      dataroot_gt: datasets/Set5/HR\n","      dataroot_lq: datasets/Set5/X2\n","      io_backend:[\n","        type: disk\n","      ]\n","      phase: test\n","      scale: 2\n","    ]\n","  ]\n","  network_g:[\n","    type: HAT\n","    upscale: 2\n","    in_chans: 3\n","    img_size: 64\n","    window_size: 16\n","    compress_ratio: 3\n","    squeeze_factor: 30\n","    conv_scale: 0.01\n","    overlap_ratio: 0.25\n","    img_range: 1.0\n","    depths: [6, 6, 6, 6, 6, 6, 6, 6]\n","    embed_dim: 96\n","    num_heads: [6, 6, 6, 6, 6, 6, 6, 6]\n","    mlp_ratio: 2\n","    upsampler: pixelshuffle\n","    resi_connection: 1conv\n","  ]\n","  path:[\n","    pretrain_network_g: experiments/train_HAT_SRx2_from_scratch/models/net_g_100.pth\n","    strict_load_g: True\n","    param_key_g: params_ema\n","    results_root: /content/drive/MyDrive/HAT2/results/HAT_SRx2\n","    log: /content/drive/MyDrive/HAT2/results/HAT_SRx2\n","    visualization: /content/drive/MyDrive/HAT2/results/HAT_SRx2/visualization\n","  ]\n","  val:[\n","    save_img: False\n","    suffix: None\n","    metrics:[\n","      psnr:[\n","        type: calculate_psnr\n","        crop_border: 2\n","        test_y_channel: True\n","      ]\n","      ssim:[\n","        type: calculate_ssim\n","        crop_border: 2\n","        test_y_channel: True\n","      ]\n","    ]\n","  ]\n","  dist: False\n","  rank: 0\n","  world_size: 1\n","  auto_resume: False\n","  is_train: False\n","\n","2023-12-31 12:32:59,222 INFO: Dataset [PairedImageDataset] - Set5 is built.\n","2023-12-31 12:32:59,222 INFO: Number of test images in Set5: 1\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","2023-12-31 12:32:59,250 INFO: Network [HAT] is created.\n","2023-12-31 12:32:59,483 INFO: Network: HAT, with parameters: 706,705\n","2023-12-31 12:32:59,483 INFO: HAT(\n","  (conv_first): Sequential(\n","    (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3)\n","    (1): Conv2d(3, 96, kernel_size=(1, 1), stride=(1, 1))\n","  )\n","  (patch_embed): PatchEmbed(\n","    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (patch_unembed): PatchUnEmbed()\n","  (pos_drop): Dropout(p=0.0, inplace=False)\n","  (layers): ModuleList(\n","    (0): RHAG(\n","      (residual_group): AttenBlocks(\n","        (blocks): ModuleList(\n","          (0): HAB(\n","            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=96, out_features=288, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=96, out_features=96, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (conv_block): CAB(\n","              (depthwise_separable_conv): Sequential(\n","                (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","                (1): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n","              )\n","              (depthwise_separable_conv1): Sequential(\n","                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n","                (1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))\n","              )\n","              (cab): Sequential(\n","                (0): Sequential(\n","                  (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","                  (1): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n","                )\n","                (1): GELU(approximate='none')\n","                (2): Sequential(\n","                  (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n","                  (1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))\n","                )\n","                (3): ChannelAttention(\n","                  (attention): Sequential(\n","                    (0): AdaptiveAvgPool2d(output_size=1)\n","                    (1): Conv2d(96, 3, kernel_size=(1, 1), stride=(1, 1))\n","                    (2): ReLU(inplace=True)\n","                    (3): Conv2d(3, 96, kernel_size=(1, 1), stride=(1, 1))\n","                    (4): Sigmoid()\n","                  )\n","                )\n","              )\n","            )\n","            (drop_path): Identity()\n","            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=96, out_features=192, bias=True)\n","              (act): GELU(approximate='none')\n","              (fc2): Linear(in_features=192, out_features=96, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (1): HAB(\n","            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=96, out_features=288, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=96, out_features=96, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (conv_block): CAB(\n","              (depthwise_separable_conv): Sequential(\n","                (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","                (1): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n","              )\n","              (depthwise_separable_conv1): Sequential(\n","                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n","                (1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))\n","              )\n","              (cab): Sequential(\n","                (0): Sequential(\n","                  (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","                  (1): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n","                )\n","                (1): GELU(approximate='none')\n","                (2): Sequential(\n","                  (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n","                  (1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))\n","                )\n","                (3): ChannelAttention(\n","                  (attention): Sequential(\n","                    (0): AdaptiveAvgPool2d(output_size=1)\n","                    (1): Conv2d(96, 3, kernel_size=(1, 1), stride=(1, 1))\n","                    (2): ReLU(inplace=True)\n","                    (3): Conv2d(3, 96, kernel_size=(1, 1), stride=(1, 1))\n","                    (4): Sigmoid()\n","                  )\n","                )\n","              )\n","            )\n","            (drop_path): DropPath()\n","            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=96, out_features=192, bias=True)\n","              (act): GELU(approximate='none')\n","              (fc2): Linear(in_features=192, out_features=96, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","        )\n","        (overlap_attn): OCAB(\n","          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","          (qkv): Linear(in_features=96, out_features=288, bias=True)\n","          (unfold): Unfold(kernel_size=(20, 20), dilation=1, padding=2, stride=16)\n","          (softmax): Softmax(dim=-1)\n","          (proj): Linear(in_features=96, out_features=96, bias=True)\n","          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=96, out_features=192, bias=True)\n","            (act): GELU(approximate='none')\n","            (fc2): Linear(in_features=192, out_features=96, bias=True)\n","            (drop): Dropout(p=0.0, inplace=False)\n","          )\n","        )\n","      )\n","      (conv): Sequential(\n","        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","        (1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","      )\n","      (patch_embed): PatchEmbed()\n","      (patch_unembed): PatchUnEmbed()\n","    )\n","    (1): RHAG(\n","      (residual_group): AttenBlocks(\n","        (blocks): ModuleList(\n","          (0-1): 2 x HAB(\n","            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","            (attn): WindowAttention(\n","              (qkv): Linear(in_features=96, out_features=288, bias=True)\n","              (attn_drop): Dropout(p=0.0, inplace=False)\n","              (proj): Linear(in_features=96, out_features=96, bias=True)\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (softmax): Softmax(dim=-1)\n","            )\n","            (conv_block): CAB(\n","              (depthwise_separable_conv): Sequential(\n","                (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","                (1): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n","              )\n","              (depthwise_separable_conv1): Sequential(\n","                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n","                (1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))\n","              )\n","              (cab): Sequential(\n","                (0): Sequential(\n","                  (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","                  (1): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n","                )\n","                (1): GELU(approximate='none')\n","                (2): Sequential(\n","                  (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n","                  (1): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1))\n","                )\n","                (3): ChannelAttention(\n","                  (attention): Sequential(\n","                    (0): AdaptiveAvgPool2d(output_size=1)\n","                    (1): Conv2d(96, 3, kernel_size=(1, 1), stride=(1, 1))\n","                    (2): ReLU(inplace=True)\n","                    (3): Conv2d(3, 96, kernel_size=(1, 1), stride=(1, 1))\n","                    (4): Sigmoid()\n","                  )\n","                )\n","              )\n","            )\n","            (drop_path): DropPath()\n","            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","            (mlp): Mlp(\n","              (fc1): Linear(in_features=96, out_features=192, bias=True)\n","              (act): GELU(approximate='none')\n","              (fc2): Linear(in_features=192, out_features=96, bias=True)\n","              (drop): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","        )\n","        (overlap_attn): OCAB(\n","          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","          (qkv): Linear(in_features=96, out_features=288, bias=True)\n","          (unfold): Unfold(kernel_size=(20, 20), dilation=1, padding=2, stride=16)\n","          (softmax): Softmax(dim=-1)\n","          (proj): Linear(in_features=96, out_features=96, bias=True)\n","          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","          (mlp): Mlp(\n","            (fc1): Linear(in_features=96, out_features=192, bias=True)\n","            (act): GELU(approximate='none')\n","            (fc2): Linear(in_features=192, out_features=96, bias=True)\n","            (drop): Dropout(p=0.0, inplace=False)\n","          )\n","        )\n","      )\n","      (conv): Sequential(\n","        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","        (1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","      )\n","      (patch_embed): PatchEmbed()\n","      (patch_unembed): PatchUnEmbed()\n","    )\n","  )\n","  (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n","  (conv_after_body): Sequential(\n","    (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","    (1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n","  )\n","  (conv_after): Sequential(\n","    (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","    (1): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n","  )\n","  (conv_before_upsample): Sequential(\n","    (0): Sequential(\n","      (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n","      (1): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (1): LeakyReLU(negative_slope=0.01, inplace=True)\n","  )\n","  (upsample): Upsample(\n","    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): PixelShuffle(upscale_factor=2)\n","  )\n","  (conv_last): Sequential(\n","    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n","    (1): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n","  )\n",")\n","2023-12-31 12:32:59,529 INFO: Loading HAT model from experiments/train_HAT_SRx2_from_scratch/models/net_g_100.pth, with param key: [params_ema].\n","2023-12-31 12:32:59,548 INFO: Model [HATModel] is created.\n","2023-12-31 12:32:59,548 INFO: Testing Set5...\n","2023-12-31 12:33:00,825 INFO: Validation Set5\n","\t # psnr: 12.6158\tBest: 12.6158 @ HAT_SRx2 iter\n","\t # ssim: 0.3264\tBest: 0.3264 @ HAT_SRx2 iter\n","\n"]}],"source":["!python hat/test.py -opt options/test/HAT_SRx2.yml"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyM8RowdLMCfYJ41R6N8Tp6J"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}